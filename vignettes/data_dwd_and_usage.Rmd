---
title: "Basic usage of the climex package"
author: "Philipp MÃ¼ller"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basic usage of the climex package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
# About
This vignette provides an introduction into the basic usage of the **climex** package:

1. The download and formatting of all the station data provided by the
   German weather service (DWD) will be described (optional, but handy if
   you haven't build up your data base yet).
2. The preprocessing of time series and fitting of the generalized
   extreme value (GEV) distribution is explained.

The usage of the shiny based climex web app will be covered in [another](./climex_app.Rmd) vignette.

# Downloading and formatting of the station data of the DWD
Since this package is intended to be used with climate data it comes along with a function to download and format all station data provided by the [German weather service (DWD)](http://www.dwd.de/DE/Home/home_node.html). I chose the daily measured time series since a higher temporal resolution would not make much sense in the context of extreme value analysis.

Before using the data please read the terms of use of the DWD at *ftp://ftp-cdc.dwd.de/pub/CDC/Terms_of_use.pdf* carefully.

This package as well as its shiny app can be used without downloading the data of the DWD. So if you already have your own data base feel free to skip to the next chapter.

## Prerequisites 
First of all the global variable **CLIMEX.PATH** has to be set. Just add the following lines to ~/.Rprofile
```{r prerequisites, cache = TRUE}
## example path. Feel free to choose your own.
CLIMEX.PATH <<- "~/R/climex/"
if ( !dir.exists( CLIMEX.PATH ) )
    dir.create( CLIMEX.PATH, recursive = TRUE )
```
This folder will contain the downloaded station data as well as the all the assets needed to deploy the climex web app locally.

## Downloading
In the second step open a new R shell, load the climex package and run the *download.data.dwd()* function to download and format the station data.
```{r downloading, eval = FALSE, cache = TRUE, dependson = "prerequisites"}
require( climex )
download.data.dwd() # this will take a while
```

This will create a folder in **CLIMEX.PATH** called **download_dwd**
containing the mirrored content of the daily measured station data
from the DWD's FTP server. Those .zip files will be extracted, parsed
and converted to
the [xts](https://cran.r-project.org/web/packages/xts/index.html)
format one after another. The parsing takes some time and can last for
several minutes depending on your machine's specifications. To avoid
saving the raw data the argument *save.downloads* can be set to
FALSE. But it is recommended to set it to TRUE since the function will
compare the time stamps of the files on the FTP server against the
ones of the local copies. Running this function another time will thus
update your existing data base without downloading all the content again.

Per default three different types of data will be extracted: the daily maximal and minimal temperature and the daily precipitation. Using the *data.type* argument one can obtain a variety of additional information from the DWD data base. There are several stations with missing data or for which specific types of measurements are not available at all. In the original time series those were set to -999 but during the formatting they are replaced by NA to avoid numerical artifacts. Please be aware that these steps will use the *mclapply* function of the **parallel** package starting threats on all your machine's cores to enhance the speed of the import.

After parsing the data it will be saved as lists of objects of the class **xts** and written to the *CLIMEX.PATH/dwd_downloads* folder in R's binary format .RData.

In addition there is the *csv.export* option exporting the lists of xts data to .csv files which can be imported into any other application. For each chosen data source in the data.type character vector a new folder will be created containing the data of each single station in a different file. 

## Loading the data
Since the data will be stored you do not have to repeat this step every time you want to load the data.

```{r dwd-loading, eval = FALSE, cache = TRUE, dependson = "downloading"}
source.data( pick.default = TRUE )
```
If the *pick.default* option is set to TRUE it will just look for the default station data (containing the maximum and minimum daily temperature as well as the daily precipitation). If the option is set to FALSE an interactive choice we be prompted instead.
This will print all existing .RData files in the
CLIMEX.PATH/dwd_downloads folder and let the user choose which one to
import. As an alternative one of course can just use the plain
*load()* function from the **base** package.

# Preprocessing and fitting of the GEV distribution
The second part of this vignette explains the basic usage of the
package's function for preprocessing the time series and fitting the
generalized extreme value (GEV) distribution. It will use the daily
maximum temperature time series of the Potsdam station provided along
with this package. This one is also contained in the data set downloaded in the first part.

```{r loading, cache = TRUE, dependson = "prerequisites"}
require( climex )
data( temp.potsdam )

## convenience function for plotting xts class time series using ggplot2
ttplot( temp.potsdam )
```
![potsdam-plot](../res/vignette-potsdam-plot.png)
## Preprocessing

The essence of the extreme value analysis is either to split a time series in blocks and extract their maximal values or to extract all data points above a specific threshold. 

#### Removing incomplete years

For the first approach it is quite important to make sure the time
series is composed of complete years only. Imagine we would extract
the annual maximum of each year in the time series but the time series
starts in autumn (and resides on the northern hemisphere). This would
result in the first annual maximum to be significant lower than all
the others and cause the analysis to yield wrong results. 

```{r incomplete-years, cache = TRUE, dependson = "loading"}

temp.potsdam.complete <- remove.incomplete.years( temp.potsdam )

ttplot( temp.potsdam.complete )

```

![potsdam-plot-complete](../res/vignette-potsdam-plot-complete.png)

#### Discard short time series


If we would deal with all the different station data of the DWD
downloaded in the first section an additional second step discarding
all time series containing less than 30 years would be required. Since
we want to extract the annual maxima we would end up with less than 30
points to fit the three GEV parameters in a later step otherwise. And
with this small number we would not be able to do decent statistics.

#### Removing seasonality

One of the basic assumptions within the extreme value theory is that
the time series is stationary and does not contain any
correlations. It is a rather bold approximation (especially in the
context of the climate change) but we will assume here that the time
series is indeed stationary and does not have any long-range correlations. But there is still a very prominent short-range correlation present in the temperature: the annual cycle. We will get rid of it by calculating the anomalies. Therefore we calculate the mean value of each day and subtract it from the individual ones. 

```{r anomalies, cache = TRUE, dependson = "incomplete-years"}

temp.potsdam.anomalies <- anomalies( temp.potsdam.complete )

ttplot( temp.potsdam.anomalies )

```
![potsdam-plot-anomalies](../res/vignette-potsdam-plot-anomalies.png)


Though you have way more data contributing to the analysis (you can
not expect the hottest day of the year to occur during winter) and
thus the asymptotic properties of the GEV distribution are more likely
fulfilled, the interpretation of the extreme events in those anomalies
is more difficult than in the raw series. 

#### Blocking

In the final step of our preprocessing we will separate the time
series in annual blocks and extract their maximal values.  

```{r blocking, cache = TRUE, dependson = "anomalies"}

## Per default the block length of the block() function will be one year
temp.potsdam.blocked <- block( temp.potsdam.anomalies )

ttplot( temp.potsdam.blocked )

```

![potsdam-plot-blocked](../res/vignette-potsdam-plot-blocked.png)


## Fitting the GEV distribution

In a last step we will fit a GEV distribution onto the time series and use the fitted result to calculate the 100 year return level of the station's temperature anomalies.

```{r fit, dependson = "blocking"}

## The result will be a list of objects similar to the output of the
## optim function.
gev.potsdam <- fit.gev( temp.potsdam.blocked )

return.level.potsdam <- return.level( gev.potsdam )
print( return.level.potsdam )

## another convenience function to easily bundle plots
multiplot( plotlist = list( ttplot( temp.potsdam.blocked ),
                           plot( gev.potsdam ) ), cols = 2,
          main = "Blocked temperature anomalies and GEV fit" )

```

![potsdam-plot-fit](../res/vignette-potsdam-plot-fit.png)


